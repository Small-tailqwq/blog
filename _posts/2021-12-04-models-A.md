---
layout: post  
title: 模块 A 复习
categories: 笔记
tags: hadoop
author: Ko_tieru
---

* content
{:toc}


## 模块A 复习

> 文中存在指令与要输入的文本在一起时，用 `$` 开头的表示指令
>
> 文中所有 `_HOME` 均为对应软件的解压目录，请自行补全
>
> hadoop、hive 这种的配置文件，其中的 `hostname` 请自行替换为 `/etc/hosts` 中存在且能链接的
> 其中根据自己节点来，比如 hive 需要已经安装了 MySQL 机器的 hostname，按需输入即可
>
> 本文并未写全，部分内容可能存在错字、歧义、无法理解……等问题，请在评论中指出，不胜感激
>
> 本文全文均收集整合自互联网或教科书，恕不声明详细来源








### 防火墙、Selinux 的关闭

- 防火墙

  > Centos 7

  ```sh
  systemctl stop firewalld.service
  &&
  systemctl disable firewalld.service
  ```

- SELinux

  ```sh
  $ vim /etc/selinux/config
  # 把 SELINUX= 的值改成 disabled
  SELINUX=disabled
  ```

  

### jdk ( *必要* )

- 解压安装包

  ```sh
  tar -zxvf jdk.tar -C /opt
  ```

- 配置环境变量

	> 根据要求看清是全局变量还是当前用户的变量
	>
	> （profile）	（.bash_profile）
	```sh
	$ vim /etc/profile
    # 或者
    $ vim /root/.bash_profile
    export JAVA_HOME=/
    export PATH=$PATH:$JAVA_HOME/bin
  ```


- 使改动生效

    ```sh
    source /etc/profile
    # 或者
    source /root/.bash_profile
    ```

- 验证

    ```sh
    java -version
    ```

### hadoop 与 hadoop HA

- 解压

    ```sh
    tar -zxvf hadoop.tar -C /opt
    ```

- 配置环境变量

    ```sh
    $ vim /etc/profile
    export HADOOP_HOME=/
    export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    ```

- 编辑 hadoop 配置文件（ *重要* ）

  > 这里要修改好几个配置文件，分别是
  > `core-site.xml`，`hdfs-site.xml`，`mapred-site.xml`，`yarn-site.xml`，`slaver`，`hadoop-env.sh`

  `core-site.xml`

    ```xml
    <property>
    <!--HDFS 主机地址-->
    <name>fs.defaultFS</name>
    <value>hdfs://主机名:9000</value>
    </property>
    <property>
    <!--Hadoop 存储目录-->
    <name>hadoop.tmp.dir</name>
    <value>/root/hadoopdate</value>
    </property>
    ```

  `hdfs-site.xml`

    ```xml
    <property>
        <!--dfs namenode web ui使用的监听地址和基本端口-->
        <name>dfs.namenode.http-address</name>
        <value>hostname:50070</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hostname:50090</value>
    </property>
    ```
  
  `mapred-site.xml`

    > 这个文件要将 `mapred-site.xml.template` 重命名得到

    ```xml
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    ```
  
  `yarn-site.xml`

    ```xml
    <property>
    	<name>yarn.resourcemanager.hostname</name>
    	<value>指定运行该服务的机器的hostname</value>
    </property>
    ```
  
  `slaves`

    ```
    填写集群所有机器的 hostname
    ```
  
  `hadoop-env.sh`

    ```sh
    # 补全文件内的 JAVA_HOME 即可
    export JAVA_HOME=/
    ```
  
- 分发文件至从节点

- 格式化 namenode

  ```sh
  hdfs namenode -format
  ```

- 启动，检查

  ```sh
  # 启动全部
  start-all.sh
  # 分步启动（dfs，yarn）
  start-dfs.sh
  start-yarn.sh
  # 停止的话把 start 替换为 stop 即可
  # 检查
  jps
  ```

  > 每个节点有 datanode，主节点有 namenode，基本就没啥问题了

#### HA 高可用

> 摆！

`core-site.xml`

```xml
<!-- zk j -->
<property>
   <name>ha.zookeeper.quorum</name>
   <value>master:2181,slave1:2181,slave2:2181</value>
</property>
```



### mysql + hive

> 由于 hive 依赖于 mysql，所以将这两放一起

#### mysql

- 解压安装包

  ```sh
  tar -zxvf mysql.tar -C /opt
  ```
- 配置环境变量

  ```sh
  $ vim /etc/profile
  export MYSQL_HOME=/
  export PATH=$PATH:$MYSQL_HOME/bin
  ```

- 创建对应的用户与用户组

  ```sh
  groupadd mysql
  useradd -r -g mysql mysql
  ```

- 为 mysql 创建目录，存放数据

  ```sh
  # 创建文件夹
  mkdir -p /var/lib/mysql
  # 设置目录所有者
  chown mysql:mysql -R /var/lib/mysql
  ```

- 配置配置文件

  ```sh
  $ vim /etc/my.cnf
  # 写入如下信息
  [mysqld]
  user=mysql
  # mysql 解压目录
  basedir=/
  datadir=/var/lib/mysql
  socket=/var/lib/mysql/mysql.sock
  character-set-server=utf8mb4
  symbolic-links=0
  
  [mysqld_safe]
  log-error=/var/lib/mysql/err.log
  pid-file=/var/lib/mysql/mysql.pid
  
  [client]
  port=3306
  socket=/var/lib/mysql/mysql.sock
  ```

- 进入 mysql 的 bin 目录下，初始化密码

  ```sh
  ./mysqld --initialize --user=mysql
  ```

- 复制 mysql 的服务项至 linux 的服务项目录中

  > mysql.server 位于 support-files 目录下

  ```sh
  cp support-files/mysql.server /etc/init.d/mysql
  ```


- 启动，登录

  ```sh
  service mysql start
  mysql -uroot -p
  ```

- 修改密码

  ```mysql
  SET PASSWORD FOR root@localhost = '密码';
  ```

- 配置远程登录

  ```mysql
  grant all privileges on *.* to 'root'@'%' identified by 'root';
  flush privileges;
  set password for "root"@"%" = '密码';
  ```

- 创建数据库

  > 此数据库为 hive 使用

  ```mysql
  create database hive;
  ```

  

---

#### hive

- 解压安装包

  ```sh
  tar -zxvf hive.tar -C /opt
  ```

- 配置 `profile`

  ```sh
  $ vim /etc/profile
  export HIVE_HOME=/
  export PATH=$PATH:$HIVE_HOME/bin
  ```

- 上传 `JDBC程序包` 至 hive 的 `lib` 目录下

  ```sh
  cp jdbc.jar /opt/hive/lib
  ```

- 在 hive 的 `conf` 目录下新建 `hive-site.xml` 

  ```xml
  <?xml version="1.0"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  <configuration>
  			<!-- jdbc连接的 URL -->
  	<property>
  		<name>javax.jdo.option.ConnectionURL</name>
  		<value>jdbc:mysql://master:3306/hive</value> 
  	</property>
  			<!-- jdbc连接的 Driver-->
  	<property>
  		<name>javax.jdo.option.ConnectionDriverName</name>
  		<value>com.mysql.jdbc.Driver</value>
  	</property>
  			<!-- jdbc连接的 username-->
  	<property>
   			<name>javax.jdo.option.ConnectionUserName</name>
   			<value>root</value>
  	</property>
  			<!-- jdbc连接的 password -->
  	<property>
  		<name>javax.jdo.option.ConnectionPassword</name>
          <value>root</value>
      </property>
  </configuration>
  ```

- 初始化元数据库

  ```sh
  schematool -initSchema -dbType mysql --verbose
  ```

- 启动 hive

  > 启动 hive 前，先确保 hadoop 启动正常

  ```sh
  hive
  ```

- 测试

  ```sql
  # 创建数据库
  create database db_test;
  # 使用数据库
  use db_test;
  #  创建表
  create table tb_test(id int,name varchar(8));
  #  显示表
  show tables;
  #  插入数据
  insert into tb_test values(1,'Mark');
  #  查询数据
  select * from tb_test;
  ```

  
### sqoop

  - 解压

    ```sh
    tar -zxvf sqoop.tar -C /opt
    ```

  - 配置

    > 分别填入 hadoop 和 hive 的安装路径

    `sqoop-env.sh`

    ```sh
    $ cp sqoop-env-template.sh sqoop-env.sh
    $ vim sqoop-env.sh
    export HADOOP_COMMON_HOME=/
    export HADOOP_MAPRED_HOME=/
    export HIVE_HOME=/
    ```

    `profile`

    ```sh
    $ vim /etc/profile
    export SQOOP_HOME=/
    export PATH=$PATH:$SQOOP_HOME/bin
    ```

  - 复制驱动程序

    > 把要使用的驱动上传至 sqoop 的 lib 目录下

    ```sh
    cp jdbc.jar /opt/sqoop/lib
    ```

  - 测试

    > 显示 localhost 下的 mysql 中的所有数据库

    ```sh
    sqoop list-databases --connect jdbc:mysql://localhost:3306 --username root --password 123456
    ```

    

### zookeeper

- 解压

  ```sh
  tar -zxvf zookeeper.tar -C /opt
  ```

- 配置

  `zoo.cfg`——zookeeper 配置文件

  ```sh
  $ vim zoo.cfg
  # 设置数据文件目录
  dataDir=/
  server.1=hostname01:2888:3888
  server.2=hostname02:2888:3888
  server.3=hostname03:2888:3888
  ```

  `myid`——编号

  > 在上面配置的 dataDir 目录中添加 myid

  ```sh
  echo '1'>myid
  ```

  `profile`

  ```sh
  $ vim /etc/profile
  export ZK_HOME=/
  export PATH=$PATH:$ZK_HOME/bin
  ```
  
  


### kafka

- 解压

  ```sh
  tar -zxvf kafka.tar -C /opt
  ```

- 配置

  `logs` 

  > 在安装目录下创建 logs 文件夹
  
  ```sh
  mkdir /opt/kafka/logs
  ```

  `server.properties`
  
  > 位于 config 文件夹中
  
  ```sh
  $ vim config/server.properties
  
  # broker的全局唯一编号，不能重复(修改处) 此处3台节点都要修改
  broker.id=0
  # 删除topic功能使能(修改处)
  delete.topic.enable=true
  # kafka运行日志存放的路径(修改处)
  log.dirs=/opt/kafka/logs
  # 配置连接Zookeeper集群地址(修改处)
  zookeeper.connect= masrter:2181,slave1:2181,slave2:2181
  ```
  
  `profile`
  
  ```sh
  $ vim /etc/profile
  export KAFKA_HOME=/
  export PATH=$PATH:$KAFKA_HOME/bin
  ```
  
- 启动

  ```sh
  kafka-server-start.sh  config/server.properties
  ```

  

### flume

- 解压

  ```sh
  tar -zxvf flume.tar -C /opt 
  ```

- 配置

  `flume.env.sh`

  ```sh
  export JAVA_HOME=/
  ```

  `profile`

  ```sh
  $ vim /etc/profile
  export FLUME_HOME=/
  export PATH=$PATH:$FLUME_HOME/bin
  ```

  
