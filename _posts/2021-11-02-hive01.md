---
layout: post  
title: 伪分布式安装hadoop
categories: 笔记
tags: hadoop
author: 土狗
---


* content
{:toc}


> 写来基本都是给自己看的，主要有些东西不巩固一下转头就忘了。写的可能有点问题，到时候再改







## Hive 介绍  

1. 基于MapReduce实现的`数据仓库工具` ，其数据存储于HDFS之上  
2. 它可以把结构化的数据映射为一张表，提供了类SQL的查询功能  

## Hive 的安装  

> 好像因为方便查询与管理的原因，使用Hive之前要安装MySQL  

### MySQL 的安装

1. 下载安装包，可以直接 `wget` 或者下载在电脑上再 `rz` 或者 `scp` 上传至 master 主机上，目录建议为 opt 目录下

2. 解压至 `/opt/` 目录下，因为目录附带了版本号啥的，所以最好 `mv` 重命名一下  

3. 创建mysql对应的用户组   `groupadd mysql` 
   创建mysql对应的用户  `useradd -r -g mysql mysql` 

4. 在 `/var/lib` 下为mysql创建目录 `mkdir mysql` 

5. 将目录所有者设为 mysql   `chown mysql:mysql -R /var/lib/mysql` 

6. `vim /etc/my.cnf` 配置mysql配置文件，写入
   
   ```
   [mysqld]
   user=mysql
   # 这里需要修改为mysql的安装目录
   basedir=/opt/module/mysql-5.7.34 
   datadir=/var/lib/mysql
   socket=/var/lib/mysql/mysql.sock
   character_set_server=utf8mb4
   symbolic-links=0
   
   [mysqld_safe]
   log-error=/var/lib/mysql/mysql.err
   pid-file=/var/lib/mysql/mysql.pid
   
   [client]
   port=3306
   socket=/var/lib/mysql/mysql.sock
   ```
   
7. 进入mysql的bin目录，初始化mysql密码并且记住 `./mysqld --initialize --user=mysql`   

   > 题外话：如果配置了profile的话其实可以不用加 `./`  

8. 将mysql的服务项复制至linux的服务项目录内 `cp support-files/mysql.server /etc/init.d/mysql` 

   启动mysql `service mysql start`

   停止mysql `service mysql stop` 

   > 题外话：/etc/init.d 是用来存放linux相关服务的，在其中的服务可以通过 `server 服务名称 操作` 的形式启动，相当于配置于之前配置profile一样  

   启动服务之后使用 `./mysql -uroot -p` 登录，密码为上一步生成的随机密码  

   密码自行替换为想要的密码 `SET PASSWORD FOR root@localhost = '密码';` 

   > 这是替换root@localhost的密码，本地登录的话没啥问题。如果需要远程登陆的话(不同网段)，需要把 `localhost` 替换为 `%` 。意味任何地方。
   > `SET PASSWORD FOR "root"@"%" = '密码';` 修改MySQL的全局密码

9. 配置远程连接 `GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root';` 
   `flush privileges;`

10. 在windows或其他远程数据库上进行链接测试，如果能够正常连接，则mysql的安装结束

## 错误

- `ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)` 
  - 登陆时添加 `-h 127.0.0.1` 
- `[Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).`
  - 在 `my.cnf` 内找到mysql的数据库，然后把这个目录mv一下。
  - 例如 `datadir=/var/lib/mysql` 那么：`cd /var/lib` 再 `mv mysql mysql_bak`





## Hive 安装  

1. 下载安装包，同样丢在 `/opt/software` 下

2. 解压安装包至 `/opt/module` 下，更改目录名为简短的目录名

3. 配置环境变量，添加 `HIVE_HOME` 为刚才的安装目录，`export PATH=$PATH:HIVE_HOME/bin` 追加PATH

   刷新 `source /etc/profile`   

4. 下载MySQL的JDBC驱动包，**解压后，**移动至Hive的lib目录下

5. 在Hive的conf目录下新建 `hive-site.xml` ，填入如下配置

   ```xml
   <?xml version="1.0"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   <configuration>
   			<!-- jdbc连接的 URL -->
   	<property>
   		<name>javax.jdo.option.ConnectionURL</name>
   		<value>jdbc:mysql://master:3306/metastore?useSSL=false</value> 
   	</property>
   			<!-- jdbc连接的 Driver-->
   	<property>
   		<name>javax.jdo.option.ConnectionDriverName</name>
   		<value>com.mysql.jdbc.Driver</value>
   	</property>
   			<!-- jdbc连接的 username-->
   	<property>
    			<name>javax.jdo.option.ConnectionUserName</name>
    			<value>root</value>
   	</property>
   			<!-- jdbc连接的 password -->
   	<property>
   		<name>javax.jdo.option.ConnectionPassword</name>
           <value>root</value>
   	</property>
   			<!-- Hive元数据存储版本的验证 -->
   	<property>
   		<name>hive.metastore.schema.verification</name>
   		<value>false</value>
   	</property>
   			<!--元数据存储授权-->
   	<property>
   		<name>hive.metastore.event.db.notification.api.auth</name>
   		<value>false</value>
   	</property>
   		<!-- Hive默认在 HDFS的工作目录 -->
   	<property>
   		<name>hive.metastore.warehouse.dir</name>
   		<value>/user/hive/warehouse</value>
   	</property>
   </configuration>
   ```

6. 启动MySQL，建立Hive的元数据库 `create database metastore;` ，退出 `quit;`

7. 初始化元数据库 `schematool -initSchema -dbType mysql --verbose`  

8. 启动Hadoop，再启动Hive  `hive`  

9. 测试

   - 创建数据库 `create database db_test;`

   - 使用数据库 `use db_test;`

   - 创建表 `create table tb_test(id int,name varchar(8));`

   - 显示表 `show tables;`
   - 插入数据 `insert into tb_test values(1,'Mark');`
   - 查询数据 `select * from tb_test;`
   - 于浏览器中打开Hadoop查看数据

10. 如顺利，则安装完成。

## 错误

- `Underlying cause: java.sql.SQLException : Access denied for user 'root'@'master' (using password: YES)
  SQL Error code: 1045`
  - 用户名和密码都没有错，结果就是死活连不上，后面发现是url的问题，url是 `mysql://master:3306/metastore` ，而mysql里对root没有`master` 这个`host`，把`master`改为`localhost`即可
  - <img src="C:\Users\email\Desktop\屏幕截图 2021-10-22 184406.png" alt="屏幕截图 2021-10-22 184406" style="zoom:75%;" />
- `Launching Job 1 out of 3
  Number of reduce tasks determined at compile time: 1
  In order to change the average load for a reducer (in bytes):
    set hive.exec.reducers.bytes.per.reducer=<number>
  In order to limit the maximum number of reducers:
    set hive.exec.reducers.max=<number>
  In order to set a constant number of reducers:
    set mapreduce.job.reduces=<number>`
  - 这段是执行插入数据时的报错，大概是没找到正在运行的hadoop

### Hive数据类型

> 待续…………




