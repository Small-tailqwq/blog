---
layout: post  
title: 伪分布式安装hadoop
categories: 笔记
tags: hadoop
author: 土狗
---


* content
{:toc}


> 缝缝补补又一年






> ~~这是一篇记录，没有对文章格式进行修饰，有很多地方可能看着很吃力，以后有空再改改~~
>
> 大部分内容为[此视频](https://www.bilibili.com/video/BV1Kf4y1z7Nw)中的内容。
>
> 更新：在改了在改了

## 准备工作  

伪分布式为本地VMware安装，镜像为linux上课用的镜像，自定义安装，安装之后配置网络静态ip，修改主机名，方便后续操作  

`vim /etc/hostname` 

在windows环境的host文件中加入主机名与相对应的ip，方便后续通过 ssh 链接。（嫌麻烦可以直接火绒改）

如果是centos6的话，需要将已近失效的 yum 源替换为阿里的镜像源：  

```
wget -O /etc/yum.repos.d/CentOS-Base.repo http://file.kangle.odata.cc/repo/Centos-6.repo
wget -O /etc/yum.repos.d/epel.repo http://file.kangle.odata.cc/repo/epel-6.repo
yum makecache
```

## 安装 JDK
去 Oracle 官网下载 JDK 的压缩包，然后上传至linux环境。

虚拟机可以在装好 `VMware tools` 后直接跨机复制粘贴，云服务器的话可以使用 `rz` 或者 `scp` 指令上传。

上传完成时候解压  `tar -xvzf jdk.tar.gz`

之后修改环境变量  `vim /etc/profile`

> 填入变量，其中 JAVA_HOME 路径自行修改
```
export JAVA_HOME=#这里填入上面解压好的jdk目录路径，如/opt/jdk1.8
export PATH=$JAVA_HOME/bin:$PATH
```

> 修改完成之后 `:wq` 保存，完成之后再 source 一下 。
```
source /etc/profile
```
>  *具体安装流程常考[此处](https://blog.csdn.net/qq_36089184/article/details/94463584)*

###  配置 Hosts 文件

修改机器的 hosts 文件 `vim /etc/hosts`

> 添加其他节点机器的 IP 与 hostname，用空格或者 TAB 隔开

### SSH 免密登录

> 大体流程：A主机生成公钥 (`id_dsa`) ，将A公钥存入B主机的 `authorized_keys` 文件内，公钥核对完成即可登录，跳过密码核验

```shell
# 生成公钥
ssh-keygen
# 配置免密登录
ssh-copy-id #这里输入需要进行免密登录的机器
ssh-copy-id hadoop102
ssh-copy-id hadoop103
# 途中可能会要求输入B主机的 root 密码，输入即可，后续不必再次输入。  
# 可选步骤
# 为 `authorized_keys` 文件添加权限，保证安全性  
chmod 600 authorized_keys
```

**这里要注意，master 也需要对自身进行免密登录**，即 `ssh-copy-id hadoop001`

## 配置时间同步 

> 如果是本地集群或者都是国内的云服务器，可以跳过这一步

```
# 查询当前时间
date
或者
clock
# 进入计划任务
crontab -e
# 每小时从这个ntp服务器获取时间
0 1 * * * /usr/sbin/ntpdate cn.pool.ntp.org
# 也可手动获取
/usr/sbin/ntpdate 192.168.1.1
(因为我的路由器固件开启了ntp功能，直接路由器上获取更方便)
```

## 上传、配置 hadoop 文件
和上传 JDK 安装包一样上传 Hadoop 的安装包，然后进行解压

为 hadoop 配置环境变量 `vim /etc/profile`  

```
export HADOOP_HOME=#这里填 hadoop 的根目录，可以解压之后 CD 再 pwd 查看
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

hadoop 的配置文件在 `hadoopX.X.X/etc/hadoop/` 目录下

需要修改的文件如下，其中内容需要根据自身环境进行修改

*另外此处的配置文件已经进行精简*

```xml
core-site.xml
    <property>
        <!--HDFS 主机地址-->
        <name>fs.defaultFS</name>
        <value>hdfs://主机名:9000</value>
    </property>
    <property>
        <!--Hadoop 存储目录-->
        <name>hadoop.tmp.dir</name>
        <value>/root/hadoopdate</value>
    </property>
<!---->
hdfs-site.xml
	<property>
        <!--dfs namenode web ui使用的监听地址和基本端口-->
        <name>dfs.namenode.http-address</name>
        <value>hadoop001:50070</value>
	</property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop003:50090</value>
    </property>
<!---->
这里需要将 mapred-site.xml.template 重命名为 mapred-site.xml
mapred-site.xml
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
<!---->
yarn-site.xml
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop101</value>
    </property>
<!---->
slaves
	hadoop101
    hadoop102
    hadoop103
<!---->
hadoop-env.sh
	export JAVA_HOME=#填入 profile 内 JAVA_HOME 的值即可
```

## 将 master 文件分发至从节点

```
# 分发 hosts 文件
scp /etc/hosts root@hadoop102:/etc/

# 分发 Hadoop 文件
scp -r /opt/hadoop/ root@hadoop102:/opt/

# 分发 /etc/profile 文件
scp /etc/profile root@hadoop102:/etc/
```




以上，配置完成


# 启动hadoop集群  
格式化 hdfs ，只需在master上执行  
**这条命令只要执行一次，多次执行会出错**

```
hdfs namenode -format
```
启动hadoop  
```
# 一键启动
start-all.sh
# 分步启动
start-dfs.sh
start-yarn.sh
停止的话把 start 换成 stop 即可
```
### 验证并排查

可以输入 `jps` 指令验证当前所运行的程序，或者采用 ip + 50070 的方式访问 hdfs 的 web 页面
